{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benardt/genealogyKPI/blob/main/genealogy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQMfj-RkJXXj"
      },
      "source": [
        "# Genealogy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "84BwJxDFcCBS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7iH5fnYMuzx"
      },
      "source": [
        "## Configuration file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2TCtBU9ZmO"
      },
      "outputs": [],
      "source": [
        "# configuration data\n",
        "\n",
        "my_config = {\n",
        "    'login': 'xxx',\n",
        "    'password': 'xxx',\n",
        "    'login_page': 'https://www.geneanet.org/connexion/',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBb33IXBNFyw"
      },
      "source": [
        "## Modules and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK_gfgUIevN5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get update\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt install ./google-chrome-stable_current_amd64.deb\n",
        "!echo $PATH\n",
        "!google-chrome --product-version\n",
        "!pip install seleniumbase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxTiRefjeX-p"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io, zipfile, re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from _plotly_utils.importers import relative_import\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfDef6NyA8xV"
      },
      "outputs": [],
      "source": [
        "# code linter\n",
        "\n",
        "!pip install pycodestyle\n",
        "!pip install --index-url https://test.pypi.org/simple/ nbpep8\n",
        "\n",
        "from nbpep8.nbpep8 import pep8\n",
        "\n",
        "# Add pep8(_ih) at the end of the code cell to see PEP8 analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vTqSspiNLqA"
      },
      "source": [
        "## Main class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5NJ7hqfa3FB"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Ancestors:\n",
        "    \"\"\"     Global class    \"\"\"\n",
        "\n",
        "    def get_polar_coordinates(self, sosa):\n",
        "        \"\"\"Sosa number to poler coordinates\n",
        "\n",
        "        Args:\n",
        "            param1 (int): The sosa number\n",
        "\n",
        "        Returns:\n",
        "            tuple (float, float): r and phi coordinates\n",
        "        \"\"\"\n",
        "\n",
        "        # calculates the generation of the individual using the sosa number\n",
        "        generation = int(np.log2(sosa))\n",
        "        # calculates the total number of individuals in the generation\n",
        "        n_total = 2**generation - 2**(generation - 1)\n",
        "        # angle phi based on the sosa number and the total number of\n",
        "        # individuals in the generation\n",
        "        phi = (sosa - 2**generation) * np.pi / n_total\n",
        "\n",
        "        return generation, phi\n",
        "\n",
        "\n",
        "    def get_coordinates(self, sosa):\n",
        "        \"\"\"Sosa number to coordinates\n",
        "\n",
        "        returns the x and y coordinates of the individual from polar coordinates\n",
        "        based on the his sosa number\n",
        "\n",
        "        Args:\n",
        "            param1 (int): The sosa number.\n",
        "\n",
        "        Returns:\n",
        "            tuple (float, float): x and y coordinates.\n",
        "\n",
        "        \"\"\"\n",
        "        radius, phi = self.get_polar_coordinates(sosa)\n",
        "        return radius * np.cos(phi), radius * np.sin(phi)\n",
        "\n",
        "    def bfs(self, node_id):\n",
        "        \"\"\"Build family graph with BFS algorithm\n",
        "\n",
        "        breadth-first search algorithm for finding all ancestors of a given node\n",
        "        in a family tree\n",
        "\n",
        "        @param: str  - node: starting node id (de-cujus)\n",
        "        \"\"\"\n",
        "        # visited = []   # List to keep track of visited nodes.\n",
        "        # visited.append(node)\n",
        "        # Initialize an empty queue and adding starting node\n",
        "        queue = []\n",
        "        queue.append(node_id)\n",
        "        # Initialize an empty queue and adding root sosa is sosa = 1\n",
        "        sosas = []\n",
        "        sosas.append(1)\n",
        "\n",
        "        # maps the sosa to its corresponding node\n",
        "        li = {}\n",
        "\n",
        "        while queue:\n",
        "            child_sosa = sosas.pop(0)\n",
        "            child_id = queue.pop(0)\n",
        "            li[child_sosa] = child_id\n",
        "\n",
        "            print(\"\\rBFS: \" + str(len(li)), end=\"\")\n",
        "            # idx = 0 or 1\n",
        "            #  + index=0 is sir (ie man)\n",
        "            #  + index=1 is dam (ie woman)\n",
        "            for idx, parent_id in enumerate(self.id_graph[child_id]):\n",
        "                # visited is not used because :\n",
        "                #   - a parent can have several child\n",
        "                #   - a parent can be multiple ancestor\n",
        "                # if parent not in visited:\n",
        "                #     visited.append(parent)\n",
        "                if parent_id != None:\n",
        "                    parent_sosa = 2 * child_sosa + idx\n",
        "                    sosas.append(parent_sosa)\n",
        "                    queue.append(parent_id)\n",
        "\n",
        "        return li\n",
        "\n",
        "    def soup_parser(self, soup):\n",
        "        \"\"\"Parse soup data got from geneanet.org\n",
        "\n",
        "        Args:\n",
        "            param1 (soup): complete web page\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"\\nSoup parser: Started!\")\n",
        "\n",
        "        texts = []\n",
        "        id_childs = []\n",
        "        id_with_noname = []\n",
        "\n",
        "        pattern = r'(?<=\\d)[^\\d^-](?=\\d+)' # ne match pas correctement\n",
        "\n",
        "        all_lis = soup.find_all(\"li\")\n",
        "\n",
        "        for li0 in all_lis:\n",
        "            if \"Génération\" in li0.text:\n",
        "                ul = li0.find(\"ul\")\n",
        "                for li in ul.find_all(\"li\"):\n",
        "                    # remove white space thousands separator\n",
        "                    string = re.sub(pattern, '', li.text)\n",
        "                    #string = li.text.replace(u'\\xa0', u'')\n",
        "                    #string = li.text.replace(u'\\x202f', u'')\n",
        "                    texts.append(string)\n",
        "\n",
        "        print(\"Soup parser - Number of lines to be processed: \", len(texts))\n",
        "\n",
        "        # Get all individuals by sosa\n",
        "        for string in texts:\n",
        "            if re.match('^[0-9]+\\s-\\s\\?\\s\\?$', string):\n",
        "                noname = re.search(r'^([0-9]+)\\s-\\s\\?\\s\\?$', string).group(1)\n",
        "                id_with_noname.append(int(noname))\n",
        "            else:\n",
        "                if re.match('^[0-9]+\\s-\\s', string):\n",
        "                    sosa = re.search(r'^([0-9]+)\\s-\\s', string).group(1)\n",
        "                    nom = re.search(r'^[0-9]+\\s-\\s(.*)', string).group(1)\n",
        "                    self.ids.append(int(sosa))\n",
        "                    id_childs.append(int(sosa))\n",
        "                    self.id_names[int(sosa)] = nom\n",
        "                if re.match('^[0-9]+\\s=>\\s[0-9]+$', string):\n",
        "                    sosa = re.search(r'^([0-9]+)\\s=>\\s[0-9]+$', string).group(1)\n",
        "                    sosa1 = re.search(r'^[0-9]+\\s=>\\s([0-9]+)$', string).group(1)\n",
        "                    self.ids.append(int(sosa))\n",
        "                    id_childs.append(int(sosa1))\n",
        "\n",
        "        # Build graph - dict child:[sir,dam]\n",
        "        max_elements = len(id_childs)\n",
        "        for sosa, child in tqdm(zip(self.ids, id_childs), total = max_elements, desc =\"Soup parser - Graph of parents being created...\"):\n",
        "            # work only with sosa in child[]\n",
        "            if sosa in id_childs:\n",
        "                # add parent if parent exist in sosas[]\n",
        "                idx_dad = self.ids.index(sosa*2)   if sosa*2   in self.ids else None\n",
        "                idx_mom = self.ids.index(sosa*2+1) if sosa*2+1 in self.ids else None\n",
        "                husb = id_childs[idx_dad] if idx_dad is not None else None\n",
        "                wife = id_childs[idx_mom] if idx_mom is not None else None\n",
        "                self.id_graph[sosa] = [husb, wife]\n",
        "\n",
        "        # Remove parent with name '? ?'\n",
        "        for key in self.id_graph:\n",
        "            for idx, parent in enumerate(self.id_graph[key]):\n",
        "                if parent in id_with_noname:\n",
        "                    self.id_graph[key][idx] = None\n",
        "\n",
        "        print(\"Soup parser: Done!\")\n",
        "\n",
        "\n",
        "    def parse_gedcom_line(self, line):\n",
        "        \"\"\"Parse a GEDCOM line and return the tag, pointers, and value (if present).\n",
        "\n",
        "        Args:\n",
        "            line (str): a single line from a GEDCOM file\n",
        "\n",
        "        Returns:\n",
        "            tuple: the tag, pointer_source, pointer_target and value (if present)\n",
        "        \"\"\"\n",
        "        # match a GEDCOM line with five optional fields:\n",
        "        # level, pointers (x2), tag, and value.\n",
        "        # Each field is separated by one or more whitespace characters.\n",
        "\n",
        "\n",
        "        # ^: Matches the start of the string.\n",
        "        # (?P<level>\\d+): Captures one or more digits as the \"level\" group.\n",
        "        # (\\s+(?P<pointer_source>@\\S+@|))?: Optionally matches one or more whitespace characters followed by an \"@\"-delimited string (captured as the \"pointer_source\" group) or an empty string.\n",
        "        # (?:\\s+(?P<tag>[A-Z]+)){1}: Matches one or more whitespace characters followed by one or more uppercase letters as the \"tag\" group.\n",
        "        # (?:\\s+(?!@)(?P<value>.+))?: Optionally matches one or more whitespace characters followed by one or more characters that are not \"@\" (captured as the \"value\" group). The negative lookahead assertion (?!@) ensures that the value does not start with \"@\".\n",
        "        # (\\s+(?P<pointer_target>@\\S+@|))?: Optionally matches one or more whitespace characters followed by an \"@\"-delimited string (captured as the \"pointer_target\" group) or an empty string.\n",
        "        # $: Matches the end of the string.\n",
        "\n",
        "\n",
        "        pattern_ged_line =  \"^\"\n",
        "        pattern_ged_line += \"(?P<level>\\d+)\" # Captures one or more digits as the \"level\" group.\n",
        "        pattern_ged_line += \"(\\s+(?P<pointer_source>@\\S+@|))?\" # match pointer @...@ ! optional\n",
        "        pattern_ged_line += \"(?:\\s+(?P<tag>[A-Z]+)){1}\" # match maj alpha char ! Mandatory\n",
        "        pattern_ged_line += \"(?:\\s+(?!@)(?P<value>.+))?\" # match string ! optional\n",
        "        pattern_ged_line += \"(\\s+(?P<pointer_target>@\\S+@|))?\" # match second pointer @...@ ! optional\n",
        "        pattern_ged_line += \"$\"\n",
        "\n",
        "        # The ^ and $ anchors ensure that the entire line is matched.\n",
        "\n",
        "        mymatch = re.match(pattern_ged_line, line)\n",
        "\n",
        "        if mymatch:\n",
        "            level = mymatch.group(\"level\")\n",
        "            ps = mymatch.group(\"pointer_source\")\n",
        "            pointer_source = ps.strip(\"@\") if ps is not None else None\n",
        "            tag = mymatch.group(\"tag\")\n",
        "            pt = mymatch.group(\"pointer_target\")\n",
        "            pointer_target = pt.strip(\"@\") if pt is not None else None\n",
        "            value = mymatch.group(\"value\")\n",
        "            return level, tag, pointer_source, pointer_target, value\n",
        "        else:\n",
        "            return None, None, None, None, None\n",
        "\n",
        "    def file_GED_parser(self, file_string):\n",
        "        \"\"\"Parse GEDCOM file\n",
        "\n",
        "        \"\"\"\n",
        "        # Initialize variables to hold individual and family data\n",
        "        individuals = {}\n",
        "        families = {}\n",
        "\n",
        "        # Iterate over each line in the GEDCOM data and parse it\n",
        "        current_tag = None\n",
        "        current_pointer = None\n",
        "\n",
        "        # Initialize flag to skip the header\n",
        "        skip_header = True\n",
        "\n",
        "        file_array = file_string.splitlines(True)\n",
        "\n",
        "        tags = {\"BIRT\": \"birth\", \"DEAT\": \"death\", \"HUSB\": \"husband\", \"WIFE\": \"wife\"}\n",
        "\n",
        "        for line in file_array:\n",
        "            level, tag, pointer_source, pointer_target, value = self.parse_gedcom_line(line)\n",
        "\n",
        "            # Skip the header\n",
        "            if tag == \"INDI\" and skip_header==True:\n",
        "                skip_header = False\n",
        "            if skip_header:\n",
        "                continue\n",
        "\n",
        "            if tag == \"INDI\":\n",
        "                current_tag = \"INDI\"\n",
        "                current_pointer = pointer_source\n",
        "                individuals[current_pointer] = {\"name\": None, \"sex\": None, \"birth\": {}, \"death\": {}, \"fams\": [], \"famc\": None}\n",
        "            elif tag == \"NAME\":\n",
        "                individuals[current_pointer][\"name\"] = value\n",
        "            elif tag == \"SEX\":\n",
        "                individuals[current_pointer][\"sex\"] = value\n",
        "            elif tag == \"BIRT\":\n",
        "                current_tag = \"BIRT\"\n",
        "            elif tag == \"DEAT\":\n",
        "                current_tag = \"DEAT\"\n",
        "            elif tag == \"FAMS\":\n",
        "                individuals[current_pointer][\"fams\"].append(pointer_target)\n",
        "            elif tag == \"FAMC\":\n",
        "                individuals[current_pointer][\"famc\"] = pointer_target\n",
        "            elif tag == \"DATE\":\n",
        "                if current_tag in [\"BIRT\", \"DEAT\"]:\n",
        "                    individuals[current_pointer][tags[current_tag]][\"date\"] = value\n",
        "            elif tag == \"PLAC\":\n",
        "                if current_tag in [\"BIRT\", \"DEAT\"]:\n",
        "                    individuals[current_pointer][tags[current_tag]][\"date\"] = value\n",
        "            elif tag == \"FAM\":\n",
        "                current_tag = \"FAM\"\n",
        "                current_pointer = pointer_source\n",
        "                families[current_pointer] = {\"husband\": None, \"wife\": None, \"marriage\": {}, \"children\": []}\n",
        "            elif tag in [\"HUSB\", \"WIFE\"]:\n",
        "                families[current_pointer][tags[tag]] = pointer_target\n",
        "            elif tag == \"MARR\":\n",
        "                current_tag = \"MARR\"\n",
        "            elif tag == \"CHIL\":\n",
        "                families[current_pointer][\"children\"].append(pointer_target)\n",
        "\n",
        "        return individuals, families\n",
        "\n",
        "\n",
        "    def file_parser(self, file_string):\n",
        "        \"\"\"Parse GEDCOM file\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        file_array = file_string.splitlines(True)\n",
        "\n",
        "        # get family\n",
        "        pattern_indi = \"^0\\s@I[0-9]+@\\sINDI$\"\n",
        "        pattern_name = \"^1\\sNAME\\s\"\n",
        "        pattern_sexe = \"^1\\sSEX\\s\"\n",
        "        pattern_fam = \"^0\\s@F[0-9]+@\\sFAM$\"\n",
        "        pattern_chil = \"^1 CHIL @I[0-9]+@$\"\n",
        "        pattern_husb = \"^1 HUSB @I[0-9]+@$\"\n",
        "        pattern_wife = \"^1 WIFE @I[0-9]+@$\"\n",
        "        chi = []\n",
        "        sir = []\n",
        "        dam = []\n",
        "\n",
        "        # Get all families\n",
        "        for string in file_array:\n",
        "            if re.match(pattern_fam, string):\n",
        "                husb, wife = None, None\n",
        "            if re.match(pattern_husb, string):\n",
        "                husb = re.search(r'^1 HUSB @I([0-9]+)@$', string).group(1)\n",
        "            if re.match(pattern_wife, string):\n",
        "                wife = re.search(r'^1 WIFE @I([0-9]+)@$', string).group(1)\n",
        "            if re.match(pattern_chil, string):\n",
        "                chil = re.search(r'^1 CHIL @I([0-9]+)@$', string).group(1)\n",
        "                chi.append(int(chil))\n",
        "                sir.append(int(husb) if husb != None else None)\n",
        "                dam.append(int(wife) if wife != None else None)\n",
        "\n",
        "        # get all individuals\n",
        "        is_indi = 1\n",
        "        for string in file_array:\n",
        "            if re.match(r'^0\\s', string) and is_indi == 0:\n",
        "                self.ids.append(id)\n",
        "                self.id_names[id] = nom\n",
        "                is_indi = 1\n",
        "            if re.match(pattern_indi, string):\n",
        "                id = int(re.search(r'^0\\s@I([0-9]+)@\\sINDI$', string).group(1))\n",
        "                nom = \"\"\n",
        "                is_indi = 0\n",
        "            if re.match(pattern_name, string):\n",
        "                nom = re.search(r'^1\\sNAME\\s(.*)$', string).group(1)\n",
        "\n",
        "\n",
        "        # Add father and mother to all individuals\n",
        "        for id in self.ids:\n",
        "            if id in chi:\n",
        "                idx = chi.index(id)\n",
        "                self.id_graph[id] = [sir[idx], dam[idx]]\n",
        "            else:\n",
        "                self.id_graph[id] = [None, None]\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, soup=None, file_string='', mode='connect'):\n",
        "\n",
        "        self.ids = []\n",
        "        # dict - id (int): name (str)\n",
        "        self.id_names = {}\n",
        "        # dict - child: [sir, dam]\n",
        "        self.id_graph = {}\n",
        "\n",
        "        if mode == \"connect\":\n",
        "            print('=> Geneanet parser')\n",
        "            if soup:\n",
        "                self.soup_parser(soup)\n",
        "            else:\n",
        "                print(\"Error: No data\")\n",
        "        elif mode == \"file\":\n",
        "            print('=> File parser')\n",
        "            self.file_parser(file_string)\n",
        "        else:\n",
        "            print('Parser error')\n",
        "\n",
        "        # ids\n",
        "        # id_names\n",
        "        # id_graph\n",
        "\n",
        "    def getName(self, sosa):\n",
        "        \"\"\"\n",
        "\n",
        "        return name of person identified by sosa number\n",
        "\n",
        "        @param: int - sosa number\n",
        "        @return: str - name of sosa\n",
        "        \"\"\"\n",
        "\n",
        "        if sosa != 0:\n",
        "            ids = self.sosa2ids[sosa]\n",
        "            name = self.id_names[ids]\n",
        "        else:\n",
        "            name = \"None\"\n",
        "        return name\n",
        "\n",
        "    def calculate_harmonic_sum(self, n):\n",
        "        total_sum = 0.0\n",
        "        for i in range(1, n):\n",
        "            total_sum = total_sum + 1.0/(2**i);\n",
        "        return total_sum;\n",
        "\n",
        "    def build_sosas(self, souche_id):\n",
        "        \"\"\"\n",
        "\n",
        "        Build 4 lists:\n",
        "            sosas{}:          dict - all sosas (with implex) and unique sosas\n",
        "            individual_occurrence[]:\n",
        "                                list - number of occurence for individual (implex)\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # 'all' and 'unique_all' work together, len('all') = len('unique_all')\n",
        "        # -> 'all' no duplicate\n",
        "        # -> 'unique_all' some duplicates, sosas from the same indiviual are\n",
        "        #    replaced by the lower sosa number\n",
        "\n",
        "\n",
        "\n",
        "        print(\"\\nBuild sosas: Breadth-first search starting!\")\n",
        "        self.sosa2ids = self.bfs(souche_id)\n",
        "        print(\"   BFS end!\")\n",
        "\n",
        "        self.sosas = {}\n",
        "\n",
        "        self.sosas['all'] = np.array(list(self.sosa2ids.keys()), dtype=int)\n",
        "        self.generation = np.log2(self.sosas['all']).astype(int)\n",
        "        self.generation[0] = 1\n",
        "        self.n_total = 2**self.generation - 2**(self.generation - 1)\n",
        "        self.generation[0] = 0\n",
        "        # angle phi based on the sosa number and the total number of\n",
        "        # individuals in the generation\n",
        "        phi = (self.sosas['all'] - 2**self.generation) * np.pi / self.n_total\n",
        "        vcalculate_harmonic_sum = np.vectorize(self.calculate_harmonic_sum)\n",
        "        phi_offset = 0.5 * np.pi * vcalculate_harmonic_sum(self.generation)\n",
        "        print(vcalculate_harmonic_sum([0,1,2,3,4,5]))\n",
        "        print(180 * phi_offset[:10] / np.pi)\n",
        "        self.coord_x = self.generation * np.cos(phi - phi_offset)\n",
        "        self.coord_y = self.generation * np.sin(phi - phi_offset)\n",
        "\n",
        "\n",
        "        all_ids = np.array(list(self.sosa2ids.values()), dtype=int)\n",
        "\n",
        "        unique_ids = np.unique(all_ids)\n",
        "        all_length = len(self.sosas['all'])\n",
        "\n",
        "        self.individual_occurrence = np.empty(all_length, dtype=int)\n",
        "        for idx, sosa in tqdm(enumerate(self.sosas['all']), total=all_length, desc =\"Multiple ancestors processing\"):\n",
        "            id = self.sosa2ids[sosa]\n",
        "            self.individual_occurrence[idx] = np.count_nonzero(all_ids == id)\n",
        "\n",
        "        self.sosas['unique_all'] = np.empty(all_length, dtype=int)\n",
        "        for idx, id in tqdm(enumerate(all_ids), total=all_length, desc =\"Unique all processing\"):\n",
        "            sosas_id = self.sosas['all'][all_ids==id]\n",
        "            self.sosas['unique_all'][idx] = np.min(sosas_id)\n",
        "\n",
        "        self.sosas['unique_only'] = np.unique(self.sosas['unique_all'])\n",
        "\n",
        "        self.unique = mya.sosas['unique_all'] == mya.sosas['all']\n",
        "\n",
        "\n",
        "    def build_parents(self):\n",
        "        \"\"\"\n",
        "        Convert the `id_graph` dictionary, which maps a unique ID to a list of its\n",
        "        parents' IDs, to a list of lists that maps each unique sosa number to its\n",
        "        parents' sosa numbers.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "\n",
        "        Parameters:\n",
        "            self (object): An instance of a class with the following attributes:\n",
        "                - `sosa2ids` (dict): A dictionary mapping unique sosa numbers to\n",
        "                their corresponding unique IDs.\n",
        "                - `sosas` (dict): A dictionary mapping different types of sosa\n",
        "                numbers to lists of sosa numbers.\n",
        "                - `id_graph` (dict): A dictionary mapping unique IDs to lists of\n",
        "                two IDs representing the parents of the individual with that ID.\n",
        "\n",
        "        Notes:\n",
        "            Assumes that there are no missing sosa numbers in `self.sosas['unique_only']`,\n",
        "            and that every sosa number in `self.sosas['unique_only']` corresponds to a\n",
        "            unique individual in the family tree represented by `self.id_graph`.\n",
        "\n",
        "            source: id_graph{} dict - {child: [sir, dam], ...}\n",
        "            target: self.parents[] list - [[], [sosa_sir2, sosa_dam2], [sosa_sir3], ...]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        sosas = list(self.sosa2ids.keys())\n",
        "        ids = list(self.sosa2ids.values())\n",
        "\n",
        "        self.parents = [[] for _ in  self.sosas['unique_only']]\n",
        "\n",
        "        # only parents of sosas are needed. Not all individuals in id_graph{}\n",
        "        for idx, sosa in enumerate(self.sosas['unique_only']):\n",
        "            id = self.sosa2ids[sosa]\n",
        "            for parent in self.id_graph[id]:\n",
        "                if parent != None:\n",
        "                    self.parents[idx] += [sosas[ids.index(parent)]]\n",
        "\n",
        "\n",
        "    def longest_ancestral_path(self, idx_parents):\n",
        "        \"\"\"Return 1D array of 'longest ancestral path'\n",
        "\n",
        "        the \"longest ancestral path\" refers to the maximum number of\n",
        "        generations that exist between an individual and their most distant\n",
        "        known ancestor within a given genealogical tree or lineage.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        nb_individuals = len(self.parents)\n",
        "        queue_of_individuals = np.linspace(\n",
        "            0, nb_individuals-1, nb_individuals, dtype=int).tolist()\n",
        "        laps = np.zeros(nb_individuals, dtype=int) - 1\n",
        "\n",
        "        while queue_of_individuals:\n",
        "            for individual in queue_of_individuals:\n",
        "                lap_of_parents = []\n",
        "                if not self.parents[individual]:\n",
        "                    laps[individual] = 0\n",
        "                    queue_of_individuals.remove(individual)\n",
        "                else:\n",
        "                    for parent in idx_parents[individual]:\n",
        "                        lap_of_parents.append(laps[parent])\n",
        "                    if -1 not in lap_of_parents:\n",
        "                        laps[individual] = max(lap_of_parents) + 1\n",
        "                        queue_of_individuals.remove(individual)\n",
        "\n",
        "        print(\"max pseudo generation: \", np.max(laps))\n",
        "\n",
        "        return laps\n",
        "\n",
        "\n",
        "    def inbreeding_preparation(self):\n",
        "\n",
        "        idx_parents = []\n",
        "        for current_parents in self.parents:\n",
        "            current_idx_parents = []\n",
        "            for parent in current_parents:\n",
        "                idx_sosa = np.where(self.sosas['unique_only'] == parent)[0][0]\n",
        "                current_idx_parents.append(idx_sosa)\n",
        "            idx_parents.append(current_idx_parents)\n",
        "\n",
        "        nb_parents = len(idx_parents)\n",
        "        laps = self.longest_ancestral_path(idx_parents)\n",
        "\n",
        "        # build 2D array for parents\n",
        "\n",
        "        P = np.zeros((nb_parents, 4), dtype=int) - 1\n",
        "        for individual, current_parents in enumerate(idx_parents):\n",
        "            for idx_parent, single_parent in enumerate(current_parents):\n",
        "                P[individual][idx_parent+1] = single_parent\n",
        "            P[individual][3] = laps[individual]\n",
        "            P[individual][0] = individual\n",
        "\n",
        "        return P\n",
        "\n",
        "\n",
        "    def inbreeding_fast(self, P):\n",
        "        \"\"\"Compute inbreeding with 'fast method'\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        nb_parents = P.shape[0]\n",
        "\n",
        "        max_lap = np.amax(P, axis=0)[3]\n",
        "\n",
        "        # first element of array is not use\n",
        "        # first individual are number 1\n",
        "        # number of individual and index in array are equal\n",
        "        f = np.zeros((nb_parents+1), dtype=float)\n",
        "        l = np.zeros((nb_parents), dtype=float)\n",
        "        d = np.zeros((nb_parents), dtype=float)\n",
        "\n",
        "        f[0] = - 1\n",
        "\n",
        "        for pseudo_generation in range(max_lap+1):\n",
        "\n",
        "            idx_indi_list = np.where(P[:, 3] == pseudo_generation)[0]\n",
        "\n",
        "            for i in idx_indi_list:\n",
        "\n",
        "                ANC_i = [i]  # list of ancestor\n",
        "                fi = -1.0\n",
        "                l[i] = 1.0\n",
        "\n",
        "                # sir and dam at index i\n",
        "                si, di = P[i, 1], P[i, 2]\n",
        "                d[i] = 0.5 - 0.25 * (f[si+1] + f[di+1])\n",
        "\n",
        "                while ANC_i:\n",
        "                    # start with youngest individual\n",
        "                    j = min(ANC_i)\n",
        "                    # sir and dam at index j\n",
        "                    sj, dj = P[j, 1], P[j, 2]\n",
        "\n",
        "                    R = 0.5 * l[j]\n",
        "                    if sj != -1:\n",
        "                        ANC_i.append(sj)\n",
        "                        l[sj] += R\n",
        "                    if dj != -1:\n",
        "                        ANC_i.append(dj)\n",
        "                        l[dj] += R\n",
        "\n",
        "                    fi += d[j]*l[j]**2\n",
        "                    l[j] = 0.0\n",
        "\n",
        "                    ANC_i.remove(j)\n",
        "\n",
        "                f[i+1] = fi\n",
        "\n",
        "        return 100*f[1:]\n",
        "\n",
        "\n",
        "    def get_indices_lap(self, P):\n",
        "        \"\"\"re order 1D array for tabular inbreeding method\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        max_lap = np.amax(P, axis=0)[3]\n",
        "        nb_parents = P.shape[0]\n",
        "        new2old = []\n",
        "        for pseudo_gene in range(max_lap+1):\n",
        "            idx_indi_list = np.where(P[:, 3] == pseudo_gene)[0]\n",
        "            idxes = np.flip(idx_indi_list).tolist()\n",
        "            new2old.extend(idxes)\n",
        "\n",
        "        old2new = []\n",
        "        for i in range(0, nb_parents):\n",
        "            old2new.append(new2old.index(i))\n",
        "\n",
        "        return new2old, old2new\n",
        "\n",
        "\n",
        "    def inbreeding_tabular(self, PA):\n",
        "        \"\"\"Compute inbreeding with 'tabular method'\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        nb_parents = PA.shape[0]\n",
        "\n",
        "        new2old, old2new = self.get_indices_lap(PA)\n",
        "\n",
        "        A = np.diag(nb_parents * [1.0])\n",
        "\n",
        "        print(\"Diag matrix done!\")\n",
        "\n",
        "        for (i, j), _ in tqdm(np.ndenumerate(A), total=nb_parents*nb_parents):\n",
        "            j_p = new2old[j]\n",
        "            if i == j:\n",
        "                has_2_parents = PA[j_p][1] != -1 and PA[j_p][2] != -1\n",
        "                if has_2_parents:\n",
        "                    id_sir_dam = old2new[PA[j_p][1]], old2new[PA[j_p][2]]\n",
        "                    A[i, j] += 0.5 * A[id_sir_dam]\n",
        "\n",
        "            elif i < j:\n",
        "                current_parents = []\n",
        "                if PA[j_p][1] != -1:\n",
        "                    current_parents.append(old2new[PA[j_p][1]])\n",
        "                if PA[j_p][2] != -1:\n",
        "                    current_parents.append(old2new[PA[j_p][2]])\n",
        "\n",
        "                for idx_tab_parent in current_parents:\n",
        "                    A[i, j] += 0.5 * A[i, idx_tab_parent]\n",
        "                    A[j, i] = A[i, j]\n",
        "\n",
        "        # flip matrix A to have youngest at bottom and left\n",
        "        #A = np.flip(A)\n",
        "        print('\\nFirst step done!')\n",
        "\n",
        "        # inbreeding coefficients are on diagonal of matrix A : 100 * (value - 1)\n",
        "        f = 100 * (A.diagonal() - 1)\n",
        "\n",
        "        f_true = np.zeros((nb_parents), dtype=float)\n",
        "        for i in range(0, nb_parents):\n",
        "            j = new2old[i]\n",
        "            f_true[j] = f[i]\n",
        "\n",
        "        return f_true\n",
        "\n",
        "\n",
        "    def inbreeding(self, mode='fast', n=4):\n",
        "        \"\"\"Compute inbreeding coefficients\n",
        "\n",
        "        Compute inbreeding coefficient for all individuals from parents data.\n",
        "        Two individuals can have the same parents. This is the starting point\n",
        "        for implex.\n",
        "\n",
        "        Returns:\n",
        "            numpy 1D array: inbreeding coefficients\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"Number of individuals to be processed: \", len(self.parents))\n",
        "        Z = self.inbreeding_preparation()\n",
        "\n",
        "        if mode == 'fast':\n",
        "            INBREEDINGS = self.inbreeding_fast(Z)\n",
        "        elif mode == 'tabular':\n",
        "            INBREEDINGS = self.inbreeding_tabular(Z)\n",
        "        else:\n",
        "            INBREEDINGS = [0]\n",
        "            print('Error: Inbredding')\n",
        "\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"x\": self.coord_x[self.unique][:n],\n",
        "            \"y\": self.coord_y[self.unique][:n],\n",
        "            \"parents\": self.parents[:n],\n",
        "            \"sosa\": self.sosas['unique_only'][:n],\n",
        "            \"name\": [self.getName(sosa) + \"<br>\" + str(inbreed) for sosa, inbreed in zip(self.sosas['unique_only'][:n],INBREEDINGS[:n])],\n",
        "            \"inbreeding\": INBREEDINGS[:n],\n",
        "            \"inbreeding_color\": [np.log(inbreeding+0.00001) for inbreeding in INBREEDINGS[:n]]\n",
        "            })\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AnNqZP_UPjb"
      },
      "source": [
        "##Roglo scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HfpAkwIUXxU"
      },
      "outputs": [],
      "source": [
        "# Get data by connecting on http://roglo.eu/roglo website\n",
        "# Authentification : Digest\n",
        "\n",
        "\n",
        "from seleniumbase import SB\n",
        "\n",
        "with SB(browser=\"chrome\", chromium_arg=\"--no-sandbox, --disable-dev-shm-usage\") as sb:\n",
        "    sb.open(\"http://roglo.eu/roglo?lang=fr;w=f;username=BenardT;password=xxxx\")\n",
        "    #sb.type(\"#_username\", my_config['login'])\n",
        "    #sb.type(\"#_password\", my_config['password'])\n",
        "    #sb.click(\"#_submit\")\n",
        "    #sb.open(\"https://www.geneanet.org/\")\n",
        "    #suffixe = '&m=A&t=N&v=50&lang=fr'\n",
        "    #r2 = sb.get_page_source()\n",
        "    #soup2 = BeautifulSoup(r2, \"html.parser\")\n",
        "    #td_tag_list = soup2.find_all(\"a\", attrs={\"gaq-event\": \"show-souche\"})\n",
        "    #print(r2)\n",
        "    r = sb.get_page_source()\n",
        "\n",
        "soup = BeautifulSoup(r, \"html.parser\")\n",
        "\n",
        "# Souche de l'arbre\n",
        "\n",
        "print(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYWCx3dlNUKP"
      },
      "source": [
        "## Geneanet scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWeMKswg6Snq"
      },
      "outputs": [],
      "source": [
        "# Get data by connecting on geneanet.org website\n",
        "\n",
        "from seleniumbase import SB\n",
        "\n",
        "with SB(browser=\"chrome\", chromium_arg=\"--no-sandbox, --disable-dev-shm-usage\") as sb:\n",
        "    sb.open(my_config['login_page'])\n",
        "    sb.type(\"#_username\", my_config['login'])\n",
        "    sb.type(\"#_password\", my_config['password'])\n",
        "    sb.click(\"#_submit\")\n",
        "    sb.open(\"https://www.geneanet.org/\")\n",
        "    suffixe = '&m=A&t=N&v=50&lang=fr'\n",
        "    r2 = sb.get_page_source()\n",
        "    soup2 = BeautifulSoup(r2, \"html.parser\")\n",
        "    td_tag_list = soup2.find_all(\"a\", attrs={\"gaq-event\": \"show-souche\"})\n",
        "    print('https:'+td_tag_list[0]['href']+suffixe)\n",
        "    sb.open('https:'+td_tag_list[0]['href']+suffixe)\n",
        "    r = sb.get_page_source()\n",
        "\n",
        "soup = BeautifulSoup(r, \"html.parser\")\n",
        "\n",
        "# Souche de l'arbre\n",
        "\n",
        "td_tag_list = soup2.find_all(\"a\", attrs={\"gaq-event\": \"show-souche\"})\n",
        "print(td_tag_list[0]['href'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rsOixQVORyR"
      },
      "source": [
        "## Instanciation and basic checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6TzNzTb1_Y-"
      },
      "outputs": [],
      "source": [
        "# Get data from local file GEDCOM (zip)\n",
        "# Paser of GEDCOM file\n",
        "def gedcom():\n",
        "    archive = zipfile.ZipFile('/content/drive/MyDrive/data/benardt_2023-01-09.zip', 'r')\n",
        "    file_data = archive.read('base.ged')\n",
        "    file_string = file_data.decode(\"utf-8\")\n",
        "    mya = Ancestors(file_string=file_string, mode='file')\n",
        "\n",
        "    return mya\n",
        "\n",
        "# Cas ascendants télécharger de Roglo\n",
        "def file():\n",
        "    roglo_archive = zipfile.ZipFile('/content/drive/MyDrive/data/roglo1.zip', 'r')\n",
        "    roglo_file_data = roglo_archive.read(roglo_archive.namelist()[0])\n",
        "    roglo_file_string = roglo_file_data.decode(\"utf-8\")\n",
        "    soup = BeautifulSoup(roglo_file_string, \"html.parser\")\n",
        "\n",
        "\n",
        "    # Get data by connecting to Geneanet website\n",
        "    return Ancestors(soup, mode='connect')\n",
        "\n",
        "\n",
        "#mya = gedcom()\n",
        "#mya.build_sosas(288)\n",
        "mya = file()\n",
        "mya.build_sosas(1)\n",
        "mya.build_parents()\n",
        "\n",
        "print(\"Number of individuals: \", len(mya.id_graph))\n",
        "\n",
        "print(\"sosas unique\", len(mya.sosas['unique_only']), mya.sosas['unique_only'])\n",
        "print(\"parents\", len(mya.parents), mya.parents)\n",
        "print(\"---------\")\n",
        "print(\"sosas all\", len(mya.sosas['all']), mya.sosas['all'])\n",
        "print(\"generation\", len(mya.generation), mya.generation)\n",
        "print(\"count\", len(mya.individual_occurrence), mya.individual_occurrence)\n",
        "print(\"unique\", len(mya.unique), mya.unique)\n",
        "\n",
        "\n",
        "for idx in range(11):\n",
        "    print(mya.sosas['all'][idx], mya.id_names[mya.sosa2ids[mya.sosas['all'][idx]]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Families parser do not work\n",
        "\n",
        "print(mya.file_GED_parser(file_string)[0]['I2343'])\n",
        "mya.file_GED_parser(file_string)[1]"
      ],
      "metadata": {
        "id": "JpndpuG69l_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx5HFKphCx4g"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = nx.DiGraph()\n",
        "G.add_nodes_from(mya.sosas['unique_only'])\n",
        "\n",
        "for idx, parents in enumerate(mya.parents):\n",
        "    for parent in parents:\n",
        "        G.add_edge(mya.sosas['unique_only'][idx], parent)\n",
        "\n",
        "print(nx.degree(G))\n",
        "print(nx.density(G))\n",
        "\n",
        "pos=nx.spring_layout(G)\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inbreedings"
      ],
      "metadata": {
        "id": "d5aCiP9IL8V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfi = mya.inbreeding(mode='fast', n=7000)"
      ],
      "metadata": {
        "id": "S5TpoXEzWryz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZZc2joXql3E"
      },
      "outputs": [],
      "source": [
        "# Figure\n",
        "fig = make_subplots(rows=1, cols=2, column_titles=[\"Inbreeding coefficient for each individual [log scale]\", \"Matrix\"])\n",
        "# fig.add_trace(go.Heatmap(z=H),\n",
        "#     row=1, col=2\n",
        "# )\n",
        "\n",
        "fig.add_trace(go.Scatter(x=dfi[\"x\"], y=dfi[\"y\"], mode='markers',\n",
        "    marker=dict(color=dfi[\"inbreeding_color\"], size=4, colorscale=\"Viridis_r\"),\n",
        "    text=dfi[\"name\"]),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis=dict(scaleanchor = \"x\", scaleratio = 1),\n",
        "    yaxis2=dict(scaleanchor = \"x2\", scaleratio = 1),\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main scatter with sosas"
      ],
      "metadata": {
        "id": "jUQCoN9PHjTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unique vs All / Individuals occurrence"
      ],
      "metadata": {
        "id": "OD9vrwabLIvB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huqUDkwb4zN7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# build DataFrame to display scatter plot with all sosas\n",
        "def wrap2lines(word):\n",
        "    '''\n",
        "    Wrap in line on 2 lines with <br> separator\n",
        "\n",
        "    @param: str\n",
        "    @return: str\n",
        "    '''\n",
        "    perfect_idx = int(len(word)/2)\n",
        "    possible_idxs = [pos for pos, char in enumerate(word) if char == ' ']\n",
        "    final_idx = min(possible_idxs, key=lambda x: abs(x-perfect_idx))\n",
        "    return word[:final_idx] + '<br>' + word[final_idx:]\n",
        "\n",
        "# build DataFrame to display scatter plot with all sosas\n",
        "\n",
        "dfp2 = pd.DataFrame({\n",
        "    \"X\": mya.coord_x,\n",
        "    \"Y\": mya.coord_y,\n",
        "    \"Generation\": mya.generation,\n",
        "    \"Sosa\": mya.sosas['all'],\n",
        "    \"Nb of sosas\": mya.individual_occurrence,\n",
        "    \"Unique sosa\": mya.sosas['unique_all'],\n",
        "    \"U\": mya.unique,\n",
        "    \"Name\": [mya.getName(sosa) for sosa in mya.sosas['unique_all']],\n",
        "    \"Sbin\": [bin(sosa) for sosa in mya.sosas['all']],\n",
        "    \"Sun_L\": [wrap2lines(str(sosa) + \" - \" + mya.getName(sosa)) for sosa in mya.sosas['all']],\n",
        "    \"Sun_P\": [wrap2lines(str(int(sosa/2)) + \" - \" + mya.getName(int(sosa/2))) for sosa in mya.sosas['all']],\n",
        "    \"Sun_V\": [360/(2**int(math.log2(sosa))) for sosa in mya.sosas['all']],\n",
        "    \"Child\": [int(sosa/2) for sosa in mya.sosas['all']],\n",
        "    \"V\": [360/(2**int(math.log2(sosa))) for sosa in mya.sosas['all']],\n",
        "    \"T\": [\"sosa: \" + str(sosa) + \" / \" + mya.getName(sosa) + \"<br>\" + str(c) for sosa,c in zip(mya.sosas['all'],mya.individual_occurrence)],\n",
        "    \"C\": [color for color in mya.individual_occurrence]\n",
        "    })\n",
        "\n",
        "# convert column in str to get palette color (not linear color)\n",
        "dfp2[\"Nb of sosas_c\"] = dfp2[\"Nb of sosas\"].astype(str)\n",
        "\n",
        "title2 = \"Unique: \" + str(mya.sosas['unique_only'].shape[0]) + \" / All: \" + str(mya.sosas['all'].shape[0])\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, column_titles=[\"Occurence\", title2])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp2[\"X\"], y=dfp2[\"Y\"], mode='markers', text=dfp2[\"T\"],\n",
        "                   marker=dict(color=dfp2[\"C\"], colorscale=\"Viridis_r\", size=4)),\n",
        "\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp2[\"X\"], y=dfp2[\"Y\"], mode='markers', text=dfp2[\"T\"],\n",
        "                   marker=dict(color=1*dfp2[\"U\"], colorscale=\"Bluered_r\", size=4)),\n",
        "\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    yaxis=dict(scaleanchor = \"x\", scaleratio = 1),\n",
        "    yaxis2=dict(scaleanchor = \"x2\", scaleratio = 1),\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descendant way for a multiple ancestor"
      ],
      "metadata": {
        "id": "Aswp89ZwLcnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe8y-DVKLZHt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_all_childs(sosa_target):\n",
        "    \"\"\"\n",
        "    get all the descendants (who exits) of an individual\n",
        "    @param: int - sosa\n",
        "    @return: list - all sosas of descendants\n",
        "    \"\"\"\n",
        "\n",
        "    idxs = [idx for idx, val in enumerate(mya.sosas['unique_all']) if val == sosa_target]\n",
        "\n",
        "    family = []\n",
        "    sosas_identical = []\n",
        "    for idx in idxs:\n",
        "        sosa = mya.sosas['all'][idx]\n",
        "        sosas_identical.append(sosa)\n",
        "        family.append(sosa)\n",
        "        child = int(sosa/2)\n",
        "        # All sosas are ancestors.\n",
        "        # So end (of while loop) is sosa = 1 [de cujus]\n",
        "        while child != 1:\n",
        "            family.append(child)\n",
        "            child = int(child/2)\n",
        "\n",
        "    return family,sosas_identical\n",
        "\n",
        "#sosa_target = 278944\n",
        "sosa_target = 224551\n",
        "#sosa_target = 266370\n",
        "#sosa_target = 33296\n",
        "\n",
        "descendants, identicals = get_all_childs(sosa_target)\n",
        "\n",
        "dfp3 = pd.DataFrame({\n",
        "    \"X\": [mya.get_coordinates(sosa)[0] for sosa in descendants],\n",
        "    \"Y\": [mya.get_coordinates(sosa)[1] for sosa in descendants],\n",
        "    \"T\": [\"sosa: \" + str(sosa) + \" / \" + mya.getName(sosa) for sosa in descendants],\n",
        "    \"C\": [1] * len(descendants)\n",
        "    })\n",
        "\n",
        "dfp4 = pd.DataFrame({\n",
        "    \"X\": [mya.get_coordinates(sosa)[0] for sosa in identicals],\n",
        "    \"Y\": [mya.get_coordinates(sosa)[1] for sosa in identicals],\n",
        "    \"T\": [\"sosa: \" + str(sosa) + \" / \" + mya.getName(sosa) for sosa in identicals],\n",
        "    \"C\": [0] * len(identicals)\n",
        "    })\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, column_titles=[\"All descendants of \"+ mya.getName(sosa_target)+\" [\" + str(sosa_target) +\"]\", \"Number of times a sosa is an ancestor\"])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp2[\"X\"][dfp2[\"U\"]==True], y=dfp2[\"Y\"][dfp2[\"U\"]==True], mode='markers', text=dfp2[\"T\"][dfp2[\"U\"]==True],\n",
        "                name=\"all unique sosas\"),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp2[\"X\"], y=dfp2[\"Y\"], mode='markers', text=dfp2[\"T\"],\n",
        "                   marker=dict(color=dfp2[\"C\"]),\n",
        "               name=\"all sosas\"),\n",
        "\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Affiche en sur-impression (par dessus) tous les descendants de \"sosa_target\"\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp3[\"X\"], y=dfp3[\"Y\"], mode='markers', text=dfp3[\"T\"],\n",
        "                    name=\"descendants\",\n",
        "                   marker=dict(color=dfp3[\"C\"])),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Affiche en sur-impression (par dessus) tous les descendants de \"sosa_target\"\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=dfp4[\"X\"], y=dfp4[\"Y\"], mode='markers', text=dfp4[\"T\"],\n",
        "                    name=\"identical\",\n",
        "                   marker=dict(color=dfp4[\"C\"],colorscale=\"Viridis_r\")),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_yaxes(\n",
        "    scaleanchor=\"x\",\n",
        "    scaleratio=1,\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sunburst"
      ],
      "metadata": {
        "id": "Wp7gzqfhOPVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tF8W-EEuWPK"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "myw1 = widgets.BoundedIntText(\n",
        "    value=4,\n",
        "    min=0,\n",
        "    max=50000000,\n",
        "    step=1,\n",
        "    description='Sosa:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "myw2 = widgets.IntSlider(\n",
        "    value=7,\n",
        "    min=0,\n",
        "    max=30,\n",
        "    step=1,\n",
        "    description='Génération:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")\n",
        "\n",
        "def draw_sun(gene,root):\n",
        "\n",
        "    df = dfp2\n",
        "    idxs = []\n",
        "    for idx, _ in enumerate(mya.sosas['all']):\n",
        "        if df['Generation'][idx] < gene and df['Sbin'][idx].startswith(bin(root)):\n",
        "            idxs.append(idx)\n",
        "\n",
        "    # fig = go.Figure(go.Sunburst(\n",
        "    #     labels=df['Sun_L'][idxs][1:],\n",
        "    #     parents=df['Sun_P'][idxs][1:],\n",
        "    #     values=df['Sun_V'][idxs][1:],\n",
        "    #     branchvalues=\"total\"\n",
        "    # ))\n",
        "\n",
        "    fig1 = go.Figure(go.Sunburst(\n",
        "        labels=df['Sosa'][idxs][1:],\n",
        "        parents=df['Child'][idxs][1:],\n",
        "        values=df['V'][idxs][1:],\n",
        "        branchvalues=\"total\",\n",
        "        hovertext=df['Name'][idxs][1:],\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(margin=dict(t=0, l=0, r=0, b=0))\n",
        "    fig1.show()\n",
        "\n",
        "ui = widgets.HBox([myw1, myw2])\n",
        "out = widgets.interactive_output(draw_sun, {'gene': myw2, 'root': myw1})\n",
        "display(ui, out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple descendant table"
      ],
      "metadata": {
        "id": "I2JPImoCLxHn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWb2z7iZ6Ve2"
      },
      "outputs": [],
      "source": [
        "\n",
        "U, C, G, N, S = [], [], [], [], []\n",
        "\n",
        "mini_nbr_doublon = 3\n",
        "\n",
        "for sosa in mya.sosas['unique_only']:\n",
        "    idx = np.where(mya.sosas['all'] == sosa)[0][0]\n",
        "    c = mya.individual_occurrence[idx]\n",
        "    if c > mini_nbr_doublon-1:\n",
        "        U.append(sosa)\n",
        "        C.append(c)\n",
        "        G.append(int(math.log2(sosa)))\n",
        "        N.append(mya.getName(sosa))\n",
        "        idxs = [idx for idx, val in enumerate(mya.sosas['unique_all']) if val == sosa]\n",
        "        S.append([mya.sosas['all'][idx] for idx in idxs])\n",
        "\n",
        "newdf = pd.DataFrame({\n",
        "    \"sosa\": U,\n",
        "    \"generation\": G,\n",
        "    \"count\": C,\n",
        "    \"name\": N,\n",
        "    \"sosas\": S\n",
        "    })\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=1,\n",
        "    specs=[[{\"type\": \"table\"}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"sosa\", \"generation\", \"count\", \"name\", \"sosas\"],\n",
        "            align=\"center\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[newdf[k].tolist() for k in newdf.columns],\n",
        "            align=\"left\"),\n",
        "        columnwidth=[1,1,1,3,8]\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False,\n",
        "    title_text=\"Most several anecesters\",\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global statistics"
      ],
      "metadata": {
        "id": "tePI5CEtMO7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPnSMXFZja_I"
      },
      "outputs": [],
      "source": [
        "\n",
        "generations_sosa, gene_tot = [], []\n",
        "Th, T, U, C, G, I = [], [], [], [], [], []\n",
        "\n",
        "for sosa in mya.sosas['unique_only']:\n",
        "    generations_sosa.append(int(np.log2(sosa)))\n",
        "\n",
        "for sosa in mya.sosas['all']:\n",
        "    gene_tot.append(int(np.log2(sosa)))\n",
        "\n",
        "generations = sorted(dfp2['Generation'].unique())\n",
        "\n",
        "for generation in generations:\n",
        "    Th.append(2**generation)\n",
        "    U.append(generations_sosa.count(generation))\n",
        "    T.append(gene_tot.count(generation))\n",
        "    C.append(int(10000*gene_tot.count(generation)/(2**generation))/100)\n",
        "    I.append(int(100*generations_sosa.count(generation)/gene_tot.count(generation)))\n",
        "\n",
        "newdf = pd.DataFrame({\n",
        "    \"generation\": generations,\n",
        "    \"unique nb\": U,\n",
        "    \"total nb\": T,\n",
        "    \"Implex\": I,\n",
        "    \"completion\": C,\n",
        "    \"theoritical nb\": Th\n",
        "    })\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    specs=[[{\"type\": \"xy\"}, {\"type\": \"violin\"}], [{\"type\": \"table\"}, {\"type\": \"sunburst\"}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(go.Bar(name='Total', x=T, y=generations, orientation='h'), row=1, col=1)\n",
        "fig.add_trace(go.Bar(name='Unique', x=U, y=generations, orientation='h'), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Scatter(name='Completition', x=C, y=generations), row=1, col=1)\n",
        "fig.data[2].update(xaxis='x5')\n",
        "fig.update_layout(xaxis5= {'anchor': 'y', 'overlaying': 'x', 'side': 'top'})\n",
        "\n",
        "fig.add_trace(go.Scatter(name='Implexe', x=I, y=generations), row=1, col=1)\n",
        "fig.data[3].update(xaxis='x6')\n",
        "fig.update_layout(xaxis6= {'anchor': 'y', 'overlaying': 'x', 'side': 'top'})\n",
        "\n",
        "fig.add_trace(go.Violin(y=dfp2[\"Generation\"][dfp2['U'] == True],\n",
        "                        side='negative', name=\"Unique\", scalegroup='Unique',\n",
        "                        line_color='blue', x0=0), row=1, col=2)\n",
        "fig.add_trace(go.Violin(y=dfp2[\"Generation\"],\n",
        "                        side='positive', name=\"Total\", scalegroup='Total',\n",
        "                        line_color='orange', x0=0), row=1, col=2)\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"generation\", \"unique nb\", \"total nb\", \"Implex\", \"completion\", \"theoritical nb\"],\n",
        "            align=\"center\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[newdf[k].tolist() for k in newdf.columns],\n",
        "            align=\"left\"),\n",
        "        columnwidth=[1, 1, 1, 1, 1, 1]\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "\n",
        "G = 9\n",
        "\n",
        "fig.add_trace(go.Sunburst(\n",
        "    labels=dfp2['Sosa'][dfp2['Generation'] < G][1:],\n",
        "    parents=dfp2['Child'][dfp2['Generation'] < G][1:],\n",
        "    values=dfp2['V'][dfp2['Generation'] < G][1:],\n",
        "    branchvalues=\"total\",\n",
        "    hovertext=dfp2['Name'][dfp2['Generation'] < G][1:],\n",
        "), row=2, col=2)\n",
        "\n",
        "fig.update_xaxes(title=\"people #\", row=1, col=1)\n",
        "fig.update_xaxes(title=\"people #\", row=1, col=2)\n",
        "fig.update_yaxes(title=\"generation #\", row=1, col=1)\n",
        "fig.update_yaxes(title=\"generation #\", row=1, col=2)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    width=900,\n",
        "    showlegend=True,\n",
        "    title_text=\"Global charts\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Javascript"
      ],
      "metadata": {
        "id": "CkbE1GlzFHWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "\n",
        "// Output\n",
        "\n",
        "let my_output_area = document.querySelector(\"#output-area\");\n",
        "\n",
        "let iDiv1 = document.createElement('div');\n",
        "iDiv1.id = 'graph';\n",
        "my_output_area.appendChild(iDiv1);\n",
        "\n",
        "let iDiv2 = document.createElement('div');\n",
        "iDiv2.id = 'message';\n",
        "my_output_area.appendChild(iDiv2);\n",
        "\n",
        "let my_output_graph = document.querySelector(\"div#output-area div#graph\");\n",
        "let my_output_message = document.querySelector(\"div#output-area div#message\");\n",
        "\n",
        "// function\n",
        "\n",
        "function calc(a, b) {\n",
        "    let c;\n",
        "\n",
        "    c = a + b;\n",
        "\n",
        "    let message = 'Res = ' + c;\n",
        "\n",
        "    return message;\n",
        "}\n",
        "\n",
        "// print\n",
        "\n",
        "my_output_graph.appendChild(document.createTextNode(calc(1, 3.3)));\n",
        "my_output_message.appendChild(document.createTextNode('end --'));\n"
      ],
      "metadata": {
        "id": "oyns5vNlBuQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRQjaZ0mHoQe"
      },
      "source": [
        "#Bibliography"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmJQrYudHuVs"
      },
      "source": [
        "Georgelis, A. (2018). Multiperspective visualization of genealogy data.\n",
        "https://www.diva-portal.org/smash/get/diva2:1242034/FULLTEXT01.pdf\n",
        "\n",
        "\n",
        "\n",
        "Ball, R., & Cook, D. (2014, February). A family-centric genealogy visualization paradigm. In Proceedings of 14th Annual Family History Technology Workshop.\n",
        "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.589.6435&rep=rep1&type=pdf\n",
        "\n",
        "\n",
        "Köhle, D. Spatio-Temporal Genealogy Visualization with WorldLines.\n",
        "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.645.7667&rep=rep1&type=pdf\n",
        "\n",
        "\n",
        "\n",
        " http://www.aviz.fr/geneaquilts\n",
        "\n",
        "\n",
        "\n",
        " Calculation of inbreeding and relationship, the tabular method http://www.ihh.kvl.dk/htm/kc/popgen/genetics/4/5.htm\n",
        "\n",
        "B Tier. Computing inbreeding coefficients quickly. Genetics Selection Evolution, 1990, 22 (4), pp.419-430. hal-00893856 https://hal.archives-ouvertes.fr/hal-00893856/\n",
        "\n",
        "\n",
        "Meuwissen, T., Luo, Z. Computing inbreeding coefficients in large populations. Genet Sel Evol 24, 305-313 (1992). https://doi.org/10.1186/1297-9686-24-4-305 https://gsejournal.biomedcentral.com/counter/pdf/10.1186/1297-9686-24-4-305.pdf\n",
        "\n",
        "\n",
        "Mehdi Sargolzaei and Hiroaki Iwaisaki, An Efficient Algorithm for Computing Inbreeding Coefficients in Large Populations},Japanese Journal of Biometrics, vol 25, pages=25-36 (2004) https://www.jstage.jst.go.jp/article/jjb/25/1/25_1_25/_pdf\n",
        "\n",
        "\n",
        "COLLEAU, J., & SARGOLZAEI, M. (2008). A proximal decomposition of inbreeding, coancestry and contributions. Genetics Research, 90(2), 191-198. doi:10.1017/S0016672307009202 https://www.cambridge.org/core/services/aop-cambridge-core/content/view/168DF022E465AC477BB39465227CCDAD/S0016672307009202a.pdf/div-class-title-a-proximal-decomposition-of-inbreeding-coancestry-and-contributions-div.pdf\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L7iH5fnYMuzx",
        "0AnNqZP_UPjb",
        "tYWCx3dlNUKP"
      ],
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1gUgC4OKDRmKL5VGlpthPI7EQqKUlvkDP",
      "authorship_tag": "ABX9TyN3V+fZWGrq5J/Z2HBAilLE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}